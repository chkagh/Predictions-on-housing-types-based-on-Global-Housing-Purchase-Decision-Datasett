# -*- coding: utf-8 -*-
"""New_Python_in_ML_Lab_7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YgRUV3BptH-VzhYRSrzgn4YlhFDIvVRL
"""

from google.colab import drive
drive.mount('/content/drive')

"""# 1) DATA DIVISION & VISUALIZATIONS

## Subsets division
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split


# data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Lab5/global_house_purchase_dataset.csv')
data = pd.read_csv('/content/drive/MyDrive/AGH/Pythong/Data/Lab2/global_house_purchase_dataset.csv')


TARGET = 'property_type'

X = data.drop(TARGET, axis=1)
y = data[TARGET]

# Spliting to train data and temp data which will be splited to validation and test set
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Spliting to test data and valid data
X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, train_size=0.7, random_state=1)

data_train = pd.concat([X_train, y_train], axis=1)
data_valid = pd.concat([X_valid, y_valid], axis=1)
data_test = pd.concat([X_test, y_test], axis=1)

"""## Plots"""

correlation_matrix = data_train.select_dtypes(include=['number']).corr()

plt.figure(figsize=(20, 15))

sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".3f", linewidths=.5)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

data.head()

print(data.columns)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

columns = data_train.columns
num_columns = len(columns)

# Define how many figures and how many subplots per figure
num_figures = 5
columns_per_figure = int(np.ceil(num_columns / num_figures))

for i in range(num_figures):
    start_idx = i * columns_per_figure
    end_idx = min((i + 1) * columns_per_figure, num_columns)
    current_columns = columns[start_idx:end_idx]

    if len(current_columns) == 0:
        continue

    # Determine optimal grid size for subplots
    num_rows = int(np.ceil(len(current_columns) / 3))  # Max 3 columns per row
    num_cols = min(len(current_columns), 3)

    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 5 * num_rows))
    fig.suptitle(f'Histograms for Features (Figure {i+1})', fontsize=16)
    axes = axes.flatten() # Flatten the array of axes for easy iteration

    for j, col in enumerate(current_columns):
        ax = axes[j]
        if data_train[col].dtype == 'object':
            # For categorical features, use countplot
            sns.countplot(y=data_train[col], ax=ax, order=data_train[col].value_counts().index)
            ax.set_title(f'Distribution of {col}', fontsize=12)
            ax.set_xlabel('Count')
            ax.set_ylabel(col)
        else:
            # For numerical features, use histplot
            sns.histplot(data_train[col], ax=ax)
            ax.set_title(f'Distribution of {col}', fontsize=12)
            ax.set_xlabel(col)
            ax.set_ylabel('Frequency')

        # Rotate x-labels if they are too long for numerical plots
        if data_train[col].dtype != 'object' and len(data_train[col].unique()) > 10:
            ax.tick_params(axis='x', rotation=45)

    # Hide any unused subplots
    for k in range(j + 1, len(axes)):
        fig.delaxes(axes[k])

    plt.tight_layout(rect=[0, 0.03, 1, 0.96]) # Adjust layout to prevent title overlap
    plt.show()

"""# 2) DATA PREPARATION

## Data Inspection
"""

data.info()

data.describe()

data.head()

"""## Unique values"""

data.nunique()

"""## Missing data"""

data.isnull().sum()

"""## Features Engineering"""

# import datetime

# # Calculate property_age
# current_year = datetime.datetime.now().year
# X_train['property_age'] = current_year - X_train['constructed_year']
# X_valid['property_age'] = current_year - X_valid['constructed_year']
# X_test['property_age'] = current_year - X_test['constructed_year']

# # Calculate price_per_sqft
# X_train['price_per_sqft'] = X_train['price'] / X_train['property_size_sqft']
# X_valid['price_per_sqft'] = X_valid['price'] / X_valid['property_size_sqft']
# X_test['price_per_sqft'] = X_test['price'] / X_test['property_size_sqft']

# X_train.info()
# X_train.head()

"""## Categorical Feature Encoding

### Removing 'Unnamed:0' & 'property_id' columns

They can cause noise
"""

X_train = X_train.drop(['property_id'], axis=1)
X_valid = X_valid.drop(['property_id'], axis=1)
X_test = X_test.drop(['property_id'], axis=1)
data_train = data_train.drop(['property_id'], axis=1)
data_valid = data_valid.drop(['property_id'], axis=1)
data_test = data_test.drop(['property_id'], axis=1)

"""### Identifying nominal features (One-Hot_ Encoding)
* country
* city
"""

X_train.head()

# from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
# import pandas as pd

# nominal_features = ['country', 'city']

# one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

# # Fit on X_train and transform all three datasets
# X_train_nominal_encoded = one_hot_encoder.fit_transform(X_train[nominal_features])
# X_valid_nominal_encoded = one_hot_encoder.transform(X_valid[nominal_features])
# X_test_nominal_encoded = one_hot_encoder.transform(X_test[nominal_features])

# # Create DataFrames for encoded nominal features with proper column names
# X_train_nominal_df = pd.DataFrame(X_train_nominal_encoded, columns=one_hot_encoder.get_feature_names_out(nominal_features), index=X_train.index)
# X_valid_nominal_df = pd.DataFrame(X_valid_nominal_encoded, columns=one_hot_encoder.get_feature_names_out(nominal_features), index=X_valid.index)
# X_test_nominal_df = pd.DataFrame(X_test_nominal_encoded, columns=one_hot_encoder.get_feature_names_out(nominal_features), index=X_test.index)

# X_train_nominal_df.info()

# X_train_nominal_df.head()

"""### Identifying ordinal features (Ordinal Encoder)
* furnishing_status

"""

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
import pandas as pd

#ordinal_features = ['furnishing_status']
ordinal_features = ['furnishing_status', 'garden', 'loan_tenure_years', 'satisfaction_score', 'neighbourhood_rating', 'connectivity_score']

furnishing_order = ['Unfurnished', 'Semi-Furnished', 'Fully-Furnished']

#ordinal_encoder = OrdinalEncoder(categories=[furnishing_order])
ordinal_encoder = OrdinalEncoder(categories=[furnishing_order, sorted(X_train['garden'].unique()),
                                            sorted(X_train['loan_tenure_years'].unique()),
                                            sorted(X_train['satisfaction_score'].unique()),
                                            sorted(X_train['neighbourhood_rating'].unique()),
                                            sorted(X_train['connectivity_score'].unique())])


X_train[ordinal_features] = ordinal_encoder.fit_transform(X_train[ordinal_features])
X_valid[ordinal_features] = ordinal_encoder.transform(X_valid[ordinal_features])
X_test[ordinal_features] = ordinal_encoder.transform(X_test[ordinal_features])

unique_cities = data['city'].unique()
print(f"There are {len(unique_cities)} unique cities.\n")
print(unique_cities)

X_train.head()

X_train = X_train.drop(['country', 'city'], axis=1)
X_valid = X_valid.drop(['country', 'city'], axis=1)
X_test = X_test.drop(['country', 'city'], axis=1)

# X_train = pd.concat([X_train.drop(columns=nominal_features), X_train_nominal_df], axis=1)
# X_valid = pd.concat([X_valid.drop(columns=nominal_features), X_valid_nominal_df], axis=1)
# X_test = pd.concat([X_test.drop(columns=nominal_features), X_test_nominal_df], axis=1)

X_train.head()

X_train.info()



"""# Applying model"""

from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

clf = Pipeline([("scaler", StandardScaler()), ("log", LogisticRegression(max_iter = 100000, random_state=1, solver='newton-cg'))])
clf.fit(X_train, y_train)

y_pred_train = clf.predict(X_train)
y_pred = clf.predict(X_valid)

from sklearn.metrics import accuracy_score
acc_train = accuracy_score(y_train, y_pred_train)
acc_val = accuracy_score(y_valid, y_pred)

print(f'Training Accuracy: {acc_train*100:.4f} %')
print(f'Validation Accuracy: {acc_val*100:.4f} %')

"""Training Accuracy: 18.1888 %
Validation Accuracy: 16.6950 %
"""

def evaluateCLF(clf, x, y_target, name = ''):
  pred = clf.predict(x)
  pred_accuracy = accuracy_score(y_target, pred)
  print(name + ' accuracy: ' + str(pred_accuracy))
  return pred

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

hiddenLayers = (25, 12)
maxIterations = 500

clf = Pipeline([("scaler", StandardScaler()), ("MLP", MLPClassifier( activation='logistic', hidden_layer_sizes=hiddenLayers, max_iter=maxIterations))])
clf.fit(X_train, y_train)

y_pred = evaluateCLF(clf, X_train, y_train, 'train')
evaluateCLF(clf, X_valid, y_valid, 'valid')
print("random:"+str(1/6))

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

y_pred = evaluateCLF(clf, X_train, y_train, 'train')
ConfusionMatrixDisplay.from_predictions(y_train, y_pred)
plt.xticks(rotation=45)
plt.show()

"""7.1-2"""

from sklearn.model_selection import cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

hiddenLayers = (25, 12)
maxIterations = 500

clf = Pipeline([("scaler", StandardScaler()), ("MLP", MLPClassifier( activation='logistic', hidden_layer_sizes=hiddenLayers, max_iter=maxIterations))])
clf.fit(X_train, y_train)


cv_values = [3, 5, 10]

for cv_val in cv_values:
    print(f"\n--- Cross-validation with cv={cv_val} ---")

    scores_class = cross_val_score(clf, X_train, y_train, cv=cv_val, scoring='accuracy')
    print(f"Classifier Accuracy (cv={cv_val}): %0.2f (+/- %0.2f)" % (scores_class.mean(), scores_class.std() * 2))

"""7.3"""

from sklearn.model_selection import cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

hiddenLayers = (25, 12)
maxIterations = 500

clf = Pipeline([("scaler", StandardScaler()), ("MLP", MLPClassifier( activation='logistic', hidden_layer_sizes=hiddenLayers, max_iter=maxIterations))])
clf.fit(X_train, y_train)

cv_val = 3
print(f"\n--- Cross-validation with cv={cv_val} ---")

scores_class = cross_val_score(clf, X_train, y_train, cv=cv_val, scoring='recall_macro')
print(f"Classifier Accuracy (cv={cv_val}): %0.2f (+/- %0.2f)" % (scores_class.mean(), scores_class.std() * 2))

from sklearn.model_selection import cross_validate

# Define scoring metrics for classification
scoring_class = ['recall_macro', 'precision_macro', 'f1_macro']

print("--- Classifier Cross-Validation Results ---")
scores_class_cv = cross_validate(clf, X_train, y_train, n_jobs=-1, cv=5, scoring=scoring_class)
for metric in scoring_class:
    mean_score = scores_class_cv[f'test_{metric}'].mean()
    std_score = scores_class_cv[f'test_{metric}'].std() * 2
    print(f"{metric.capitalize()}: %0.2f (+/- %0.2f)" % (mean_score, std_score))

"""7.4 Grid Search"""

import multiprocessing

cores = multiprocessing.cpu_count() # Count the number of cores in a computer
cores

from sklearn.preprocessing import StandardScaler
X_train_scaled = StandardScaler().fit_transform(X_train)
X_valid_scaled = StandardScaler().fit_transform(X_valid)
X_test_scaled = StandardScaler().fit_transform(X_test)

from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPRegressor, MLPClassifier

clf =  MLPClassifier(activation='tanh', solver='sgd')

parameters = [
  {'hidden_layer_sizes':((15,4,8), (30,5,10), (15,10,5), (15,7), (30,15), (8,15)),
  'activation':('logistic', 'tanh', 'relu'),
  'solver':('sgd', 'adam'),
  'learning_rate':('adaptive','constant'),
  'max_iter':(500, 2500, 5000)}
                ]

grid_search = GridSearchCV(clf, parameters, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train_scaled, y_train)

cv_res = pd.DataFrame(grid_search.cv_results_) # or use DataFrame
display(cv_res) # to display results as a table

parameters_to_analyze = ['hidden_layer_sizes', 'learning_rate', 'max_iter', 'solver', 'activation']

for param_name in parameters_to_analyze:
    print(f"\n--- Mean mean_test_score for {param_name}: ---")
    # Extract the parameter value from the 'params' dictionary for grouping
    # Using apply(lambda x: x[param_name]) to get the specific parameter value
    # Then group by these extracted values and calculate the mean of 'mean_test_score'
    grouped_scores = cv_res.groupby(cv_res['params'].apply(lambda x: x[param_name]))['mean_test_score'].mean()
    print(grouped_scores)

